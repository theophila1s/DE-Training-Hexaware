{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVGIQi8h6w2t",
        "outputId": "e055ef16-92ef-4417-a47b-f5f90ff9ff10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"FileTypesExample\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load text file\n",
        "txt_df = spark.read.text(\"/example.txt\")  # Ensure example.txt is uploaded\n",
        "\n",
        "# Print schema\n",
        "txt_df.printSchema()\n",
        "\n",
        "# Show data\n",
        "txt_df.show(truncate=False)\n",
        "\n",
        "# Check data types\n",
        "print(\"TXT Schema:\", txt_df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va4aL8wvAC9T",
        "outputId": "89314de1-c7d0-4751-c9ee-a3f26fcb02cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+---------------------------------------------------------------------------+\n",
            "|value                                                                      |\n",
            "+---------------------------------------------------------------------------+\n",
            "|Spark SQL was first released in Spark 1.0 (May, 2014).                     |\n",
            "|Initial committed by Michael Armbrust & Reynold Xin from Databricks.       |\n",
            "|Spark introduces a programming module for structured data processing called|\n",
            "|Spark SQL.                                                                 |\n",
            "+---------------------------------------------------------------------------+\n",
            "\n",
            "TXT Schema: [('value', 'string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_df = spark.read.csv(\"/example.csv\", header=True, inferSchema=True)  # Ensure example.csv is uploaded\n",
        "\n",
        "# Print schema\n",
        "csv_df.printSchema()\n",
        "\n",
        "# Show data\n",
        "csv_df.show()\n",
        "\n",
        "# Check data types\n",
        "print(\"CSV Schema:\", csv_df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-4CnJc6AlKz",
        "outputId": "97328b36-377a-4cdc-a45d-06451e13d14d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            "\n",
            "+-------+---+------+-----------+\n",
            "|   Name|Age|Gender|       City|\n",
            "+-------+---+------+-----------+\n",
            "|  Alice| 34|  Male|   New York|\n",
            "|    Bob| 45|  Male|Los Angeles|\n",
            "|Shreeja| 29|Female|  Bengaluru|\n",
            "|Lavanya| 25|Female|       Pune|\n",
            "+-------+---+------+-----------+\n",
            "\n",
            "CSV Schema: [('Name', 'string'), ('Age', 'int'), ('Gender', 'string'), ('City', 'string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/employee.json\", \"w\") as f:\n",
        "    f.write('{\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\\n')\n",
        "    f.write('{\"name\": \"Bob\", \"age\": 25, \"city\": \"Los Angeles\"}\\n')"
      ],
      "metadata": {
        "id": "V-njxW7tCB0_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_df = spark.read.json(\"/employee.json\")\n",
        "json_df.printSchema()\n",
        "json_df.show()\n",
        "print(\"JSON Schema:\", json_df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXT7w0eHFY2U",
        "outputId": "ab2a26ba-c6e5-45c9-86e5-33dee160f788"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n",
            "+---+-----------+-----+\n",
            "|age|       city| name|\n",
            "+---+-----------+-----+\n",
            "| 30|   New York|Alice|\n",
            "| 25|Los Angeles|  Bob|\n",
            "+---+-----------+-----+\n",
            "\n",
            "JSON Schema: [('age', 'bigint'), ('city', 'string'), ('name', 'string')]\n"
          ]
        }
      ]
    }
  ]
}